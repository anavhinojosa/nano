!pip install pandas numpy scikit-learn matplotlib
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
import matplotlib.pyplot as plt

# Load the dataset
file_path = 'Nanoparticle_database.csv'  

# Display the first few rows
print(data.head())
# Check for missing values
print(data.isnull().sum())

# Clean the data:
from sklearn.impute import SimpleImputer

# Initialize the imputer with the mean strategy
imputer = SimpleImputer(strategy='mean')

# Apply the imputer to X
X = imputer.fit_transform(X)

# Convert back to DataFrame (optional, for checking)
X = pd.DataFrame(X, columns=['Average particle size (nm)', 'Nanoparticle volume fraction (%)', 
                             'Base fluid temperature (K)', 'Nanoparticle specific heat capacity (J/kg \cdot K)', 
                             'Base fluid specific heat capacity (J/kg \cdot K)'])

# Check for missing values after imputation
print("Missing values after imputation:")
print(X.isnull().sum())
# Print data types of each column
print("Data types of each column in X:")
print(X.dtypes)
print("First few rows of X after imputation:")
print(X.head())

# Check for missing values in y
print("Missing values in y:", y.isnull().sum())
# Combine X and y into a single DataFrame
data_combined = pd.concat([X, y], axis=1)

# Drop rows with NaN in y
data_combined = data_combined.dropna(subset=['Nanofluid specific heat capacity (J/kg \cdot K)'])

# Separate X and y again
X = data_combined.drop(columns=['Nanofluid specific heat capacity (J/kg \cdot K)'])
y = data_combined['Nanofluid specific heat capacity (J/kg \cdot K)']
# Fill missing values in y with the mean
y.fillna(y.mean(), inplace=True)

# Fill missing values in y with the mean
y.fillna(y.mean(), inplace=True)
print("Missing values in y after handling:", y.isnull().sum())
# end of cleaning data
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model
rf_model.fit(X_train, y_train)
# Make predictions
y_pred = rf_model.predict(X_test)

# Calculate evaluation metrics
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error (MAE): {mae}')
print(f'R² Score: {r2}')
# Make predictions
y_pred = rf_model.predict(X_test)

# Calculate evaluation metrics
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Absolute Error (MAE): {mae}')
print(f'R² Score: {r2}')

#plot
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.xlabel('Actual Specific Heat Capacity')
plt.ylabel('Predicted Specific Heat Capacity')
plt.title('Actual vs Predicted Specific Heat Capacity')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', color='red')
plt.show()
